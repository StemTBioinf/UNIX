<script> https://github.com/Mottie/GitHub-userscripts/blob/master/github-collapse-in-comment.user.js </script>

## Using UNIX and the Lunarc LSEN HPC system

The purpose of this workshop is to get you familiar with the UNIX environment and using the Lunarc LSENS system for high-performance computing. By the time you are done here, you should be able to do the following:

- Log into Luarc using the ThinLinc client to enter the Lunarc desktop environment
- Navigate the file structure and move files/folders around.
- Queue up a job to run on the compute nodes (a job for example could be a sequence alignment from an NGS run)

## Get your computer ready!

We need you to have installed the ThinLink client on the computer you bring to the workshop.
You can see this as a first exercise: Use google to learn about ThinLink, where to get it and how to install it for your system.  
Use this knowledge to install it ;-)

<details><summary>I can not use Google!</summary>
<p>
<a href="https://lunarc-documentation.readthedocs.io/en/latest/using_hpc_desktop/" target='_blank' >google: lunarc thinlink # first entry</a>
</p>
</details>

Security is a high priority an aurora and this starts with the server rejecting connections from all but the BMC network. So you can only use Aurora from within the BMC network.
TODO: SOMEONE ADD THE VPN INFO HERE?
 

### Connection info

- Server: aurora-ls2.lunarc.lu.se
- Username: your aurora username
- Password: your aurora password

One time password:
The one time password is created on your phone using either the 'Pocket Pass' app for MacOS or the '' app for android based phones.

## The ThinLink Interface

The window manager is based on [MATE Desktop](https://mate-desktop.org/).

Most scientific programs for Bioinformaticians come without a graphical user interface and therefore the 'Terminal' is our most basic, but likely most used tool.
The 'Terminal' is so important that the MATE desktop has a direcxt link to it in the top panel between the file explorer and the web browser icon.

In fact you could just click on that as we will use it extensively in this course.


### Data storage

All user data should be stored on our data server - not in your home folder!


```bash
# home folder
ls ~
## data server (your folder) 
me=`whoami`
ls /projects/fs1/$me
```
<details><summary>More info on that</summary>
<p>
<ul>
<li> '~' is an inbuilt variable that points to your home directory.</li>
<li> 'me=`whoami`' creates a local variable with the output of the whoami (speak 'who am I') program which returns our username (stefanl for me) </li>
<li> ls /projects/fs1/$me simply lists the contents of the folder e.g. /projects/fs1/stefanl</li>
</ul>
</p>
</details>


### Create a symbolic link to the data folder in your home directory.

I am rather lazy and therefore would also recommend you to create a symbolic link to this folder in your home directory.

In the Terminal use the 'ln' program to create a link from '/projects/fs1/"your username"' to '~/NAS'.

<details><summary>How to create this link</summary>
<p>
This will make the data storage path available as ~/NAS</BR>

<pre><code class="bash">ln -s /projects/fs1/"your username" ~/NAS
</code></pre>
</p>
</details>


## Common programs:

Every Linux/Unix installation has a basic set of tools installed that are extremely helpful for the daily work.

Today we already used cd and ls which moves between directories respectively links files to other locations.

Other very commonly used programs are ls, touch, cp, mkdir, mv, rm, echo, cat, cut, head, tail, grep, wc, tar, gzip, gunzip and others.

You can read up on these programs using:


```bash
# get info to a program
man "program name"
```

Unfortunately this is not working on aurora. The internet also contains all this information.

### Create files / directories

Go to your data server folder, create a folder with the name 'TestFileCreation' and create a file named README.txt in the folder. The file should contain the string 'Here we play with files and folders'.

As a hint - you need the tools cd, mkdir and echo.

Just writing the program name without additional information into the Terminal gives help on how to use the program.

<details><summary>Solution</summary>
<p>
<pre><code class="bash">cd ~/NAS
mkdir TestFileCreation
cd TestFileCreation
echo 'Here we play with files and folders' > README.txt
</code></pre>
</p>
</details>

### Extract information from a file

On aurora we store genome information in a special folder that is readable by all users:


```bash
ls /projects/fs1/common/genome/lunarc/
# e.g. gencode information mv19
ls /projects/fs1/common/genome/lunarc/genomes/mouse/GRCm38.p6/gencode.vM19.chr_patch_hapl_scaff.annotation.gtf
```

These folders soon get very long and therefore I recommend you to create links (again):

Link the /projects/fs1/common/genome/lunarc folder to your home directory.

<details><summary>How to create this link</summary>
<p>
This will make the data storage path available as ~/lunarc</BR>

<pre><code class="bash">ln -s /projects/fs1/common/genome/lunarc/ ~/lunarc
</code></pre>
</p>
</details>

Now get some information about the gencode.vM19.chr_patch_hapl_scaff.annotation.gtf file using ls, wc, head and tail.

Perfect - now you know how big these gtf files are and which internal structure they have. It would be quite interesting to get information out of the file - or?

Get all information regarding Gapdh out of the file (using grep) and put this information in a new 'Gapdh.gtf' file in your TestFileCreation folder. And as this is a step you might forget after some time I recommend you to store how you did that in the file 'Gapdh.gtf.log'.

<details><summary>How to ...</summary>
<p>
<pre><code class="bash">cd ~/NAS/TestFileCreation
grep Gapdh ~/lunarc/genomes/mouse/GRCm38.p6/gencode.vM19.chr_patch_hapl_scaff.annotation.gtf > Gapdh.gtf
echo 'grep Gapdh ~/lunarc/genomes/mouse/GRCm38.p6/gencode.vM19.chr_patch_hapl_scaff.annotation.gtf > Gapdh.gtf' > Gapdh.gtf.log
</code></pre>
</p>
</details>

<details><summary>For specialists please explain ;-)</summary>
<p>
<pre><code class="bash">history | tail -n2 | head -n1 | perl -lane 'shift(@F); print join(" ", @F);' > Gapdh.gtf.log
</code></pre>
</p>
</details>

## Pipes

Pipes are a Linux/Unix way to copy information between program calls. Pipes are used all the time in Bioinformatics and therefore the [Pipe concept needs explanation](https://en.wikipedia.org/wiki/Pipeline_(Unix)). 

You have used pipes all the time as each | and > is 'piping' information from one process to another or to a file.

I do not want to go into detail here, but read up on that it might become important for you later on.

## Extract with more conditions

If you would want to extract all genes from a certain chomosome area you need more than just one grep.
You could use awk here!

Task: get all genes from chr4 between bp 10000002 and 19000002 and store the info in the file 'chr4_10000002_19000002.genes.gtf'.

<details><summary>Use awk to get gene information</summary>
<p>
<pre><code class="bash">fname=~/lunarc/genomes/mouse/GRCm38.p6/gencode.vM19.chr_patch_hapl_scaff.annotation.gtf
grep -w gene $fname | awk '{ if ( $1 == "chr4" & $4 < 19000002 & $5 > 10000002 ) {print}}' > chr4_10000002_19000002.genes.gtf
</code></pre>
</p>
</details>

Have you thought about the .log file? No - do that ;-)

I am sure you can think of more problems that can be solved like that.

# Second half - Using Installed Software

## Software installed on aurora

Aurora uses the [module system](https://www.nersc.gov/users/software/user-environment/modules/) to provide multiple versions of one program to all users.



## Usage of the compute nodes

The computer the ThinLink client connects you to is our frontend. ONE computer for all of you. So do not run computing intensive tasks there - NEVER.

Instead you need to use our computing nodes to run heavy workload.


